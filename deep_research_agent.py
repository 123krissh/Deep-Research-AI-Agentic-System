from dotenv import load_dotenv
import os
from typing import TypedDict

from tavily import TavilyClient
from langchain_openai import ChatOpenAI  # âœ… Correct import
from langgraph.graph import StateGraph, END

# ------------------------
# ğŸ” Load API keys
# ------------------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

# ------------------------
# ğŸ”§ Clients
# ------------------------
tavily = TavilyClient(api_key=TAVILY_API_KEY)
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7, api_key=OPENAI_API_KEY)

# ------------------------
# ğŸ§¾ State Schema
# ------------------------
class ResearchState(TypedDict):
    query: str
    data: str

# ------------------------
# ğŸ§  Research Agent
# ------------------------
def research_agent(state: ResearchState) -> ResearchState:
    print("[ğŸ”¹] Research Agent is collecting data...")
    results = tavily.search(state["query"], max_results=5)
    docs = [r["content"] for r in results["results"]]
    compiled = "\n\n".join(docs)
    return {"query": state["query"], "data": compiled}

# ------------------------
# âœï¸ Answer Agent
# ------------------------
def answer_agent(state: ResearchState) -> str:
    print("[âœï¸] Drafting Agent is generating the answer...")
    prompt = f"""
    You are a research assistant. Based on the following data, write a detailed, well-researched response:

    {state['data']}
    """
    return llm.invoke(prompt)

# ------------------------
# ğŸ”„ LangGraph Setup
# ------------------------
def create_graph():
    builder = StateGraph(ResearchState)  # âœ… Schema added here
    builder.add_node("Research", research_agent)
    builder.add_node("Drafting", answer_agent)
    builder.set_entry_point("Research")
    builder.add_edge("Research", "Drafting")
    builder.add_edge("Drafting", END)

    return builder.compile()

# ------------------------
# ğŸš€ Run
# ------------------------
if __name__ == "__main__":
    query = input("ğŸ“ Enter your research query: ")
    graph = create_graph()
    result = graph.invoke({"query": query})
    print("\nâœ… Final Answer:\n")
    print(result)